<chapter id="luplanning-1"><title>Solaris Live Upgrade (Planning)</title><highlights><para>This
chapter provides guidelines and requirements for review before installing
and using Solaris Live Upgrade. You also should review general information
about upgrading in <olink targetdoc="solinstallpbiu" targetptr="emyaq" remap="external"><citetitle remap="section">Upgrade Planning</citetitle> in <citetitle remap="book">Solaris Express Installation Guide: Planning for Installation and Upgrade</citetitle></olink>.
This chapter contains the following sections:</para><itemizedlist><listitem><para><olink targetptr="preconfig-17" remap="internal">Solaris Live Upgrade Requirements</olink></para>
</listitem><listitem><para><olink targetptr="luplanning-12" remap="internal">Upgrading a System With Packages
or Patches</olink></para>
</listitem><listitem><para><olink targetptr="luplanning-11" remap="internal">Guidelines for Creating File
Systems With the lucreate Command</olink></para>
</listitem><listitem><para><olink targetptr="luplanning-50" remap="internal">Guidelines for Selecting
Slices for File Systems</olink></para>
</listitem><listitem><para><olink targetptr="luplanning-4" remap="internal">Customizing a New Boot Environment's
Content</olink></para>
</listitem><listitem><para><olink targetptr="luplanning-10" remap="internal">Synchronizing Files Between
Boot Environments</olink></para>
</listitem>
</itemizedlist>
</highlights><sect1 id="preconfig-17"><title>Solaris Live Upgrade Requirements</title><para>Before you install and use Solaris Live Upgrade, become familiar with
these requirements.</para><sect2 id="luplanning-7"><title>Solaris Live Upgrade System Requirements</title><para>Solaris Live Upgrade is included in the Solaris software. You need to
install the Solaris Live Upgrade packages on your current OS. The release
of the Solaris Live Upgrade packages must match the release of the OS you
are upgrading to. For example, if your current OS is the Solaris 9 release
and you want to upgrade to the Solaris Express 5/07 release, you need
to install the Solaris Live Upgrade packages from the Solaris Express 5/07 release.</para><para><olink targetptr="luplanning-tbl-20" remap="internal">Table 3&ndash;1</olink> lists releases
that are supported by Solaris Live Upgrade.</para><table frame="topbot" id="luplanning-tbl-20"><title>Supported Solaris Releases</title><tgroup cols="2" colsep="0" rowsep="0"><colspec colname="colspec1" colwidth="50.00*"/><colspec colname="colspec2" colwidth="50*"/><thead><row rowsep="1"><entry><para>Your Current Release</para>
</entry><entry><para>Compatible Upgrade Release</para>
</entry>
</row>
</thead><tbody><row><entry><para>Solaris 8 OS</para>
</entry><entry><para>Solaris 8, 9, or any Solaris 10 release</para>
</entry>
</row><row><entry><para>Solaris 9 OS</para>
</entry><entry><para>Solaris 9 or any Solaris 10 release</para>
</entry>
</row><row><entry rowsep="1"><para>Solaris 10 OS</para>
</entry><entry rowsep="1"><para>Any Solaris 10 release</para>
</entry>
</row>
</tbody>
</tgroup>
</table>
</sect2><sect2 id="luplanning-21"><title>Installing Solaris Live Upgrade</title><para>You can install the Solaris Live Upgrade packages by using the following:</para><itemizedlist><listitem><para>The <command>pkgadd</command> command. The Solaris Live Upgrade
packages are <literal>SUNWlucfg</literal>, <literal>SUNWlur</literal>, and <literal>SUNWluu</literal>, and these packages  must be installed in that order.</para>
</listitem><listitem><para>An installer on the Solaris Operating System DVD, the Solaris Software - 2 CD,
or a network installation image. </para>
</listitem>
</itemizedlist><para>Be aware that the following patches might need to be installed for the
correct operation of Solaris Live Upgrade.</para><informaltable frame="topbot" pgwide="1"><tgroup cols="2" colsep="0" rowsep="0"><colspec colwidth="50*"/><colspec colwidth="50*"/><thead><row rowsep="1"><entry><para>Description</para>
</entry><entry><para>For More Information</para>
</entry>
</row>
</thead><tbody><row><entry><para><emphasis role="strong">Caution</emphasis>: Correct operation
of Solaris Live Upgrade requires that a limited set of patch revisions be
installed for a particular OS version. Before installing or running Solaris
Live Upgrade, you are required to install these patches. </para><note arch="x86"><para>If this set of patches is not installed, Solaris Live
Upgrade fails and you might see the following error message. If you don't
see the following error message, necessary patches still might not be installed.
Always verify that all patches listed on the SunSolve info doc have been installed
before attempting to install Solaris Live Upgrade.</para><screen>ERROR: Cannot find or is not executable: 
&lt;/sbin/biosdev>.
ERROR: One or more patches required 
by Live Upgrade has not been installed.</screen>
</note><para>The patches listed in info doc 72099 are subject to change at any time.
These patches potentially fix defects in Solaris Live Upgrade, as well as
fix defects in components that Solaris Live Upgrade depends on. If you experience
any difficulties with Solaris Live Upgrade, please check and make sure that
you have the latest Solaris Live Upgrade patches installed.</para>
</entry><entry><para>Ensure that you have the most recently updated patch list by consulting <ulink url="http://sunsolve.sun.com" type="text">http://sunsolve.sun.com</ulink>.
Search for the info doc 72099 on the SunSolve web site.</para>
</entry>
</row><row><entry><para>If you are running the Solaris 8 or 9 OS, you might not be able to run
the Solaris Live Upgrade installer.  These releases do not contain the set
of patches needed to run the Java 2 runtime environment. You must have the
recommended patch cluster for the Java 2 runtime environment recommended to
run the Solaris Live Upgrade installer and install the packages.</para>
</entry><entry><para>To install the Solaris Live Upgrade packages, use the <command>pkgadd</command> command.
Or install, for the Java 2 runtime environment, the recommended patch cluster.
The patch cluster is available on <ulink url="http://sunsolve.sun.com" type="text">http://sunsolve.sun.com</ulink>.</para>
</entry>
</row>
</tbody>
</tgroup>
</informaltable><para>For instructions about installing the Solaris Live Upgrade software,
see <olink targetptr="lucreate-8" remap="internal">Installing Solaris Live Upgrade</olink>.</para><sect3><title>Required Packages</title><para>If you have
problems with Solaris Live Upgrade, you might be missing packages. In the
following table, check that your OS has the listed packages , which are required
to use Solaris Live Upgrade.</para><para>For the Solaris 10 release:</para><itemizedlist><listitem><para>If you install one of the following software groups, these
software groups contain all the required Solaris Live Upgrade packages.</para><itemizedlist><listitem><para>Entire Solaris Software Group Plus OEM Support</para>
</listitem><listitem><para>Entire Solaris Software Group</para>
</listitem><listitem><para>Developer Solaris Software Group</para>
</listitem><listitem><para>End User Solaris Software Group</para>
</listitem>
</itemizedlist>
</listitem><listitem><para>If you install one of these Software Groups, then you might
not have all the packages required to use Solaris Live Upgrade.</para><itemizedlist><listitem><para>Core System Support Software Group</para>
</listitem><listitem><para>Reduced Network Support Software Group</para>
</listitem>
</itemizedlist>
</listitem>
</itemizedlist><para>For information about software groups, see <olink targetdoc="solinstallpbiu" targetptr="esimo" remap="external"><citetitle remap="section">Disk Space Recommendations for Software Groups</citetitle> in <citetitle remap="book">Solaris Express Installation Guide: Planning for Installation and Upgrade</citetitle></olink>.</para><table frame="topbot" id="luplanning-tbl-4"><title>Required Packages for Solaris
Live Upgrade</title><tgroup cols="3" colsep="0" rowsep="0"><colspec colname="colspec2" colwidth="33*"/><colspec colname="colspec8" colwidth="33.00*"/><colspec colname="colspec0" colwidth="33.00*"/><thead><row rowsep="1"><entry><para>Solaris 8 Release</para>
</entry><entry><para>Solaris 9 Release</para>
</entry><entry><para>Solaris 10 Release</para>
</entry>
</row>
</thead><tbody><row><entry><para>SUNWadmap</para>
</entry><entry><para>SUNWadmap</para>
</entry><entry><para>SUNWadmap</para>
</entry>
</row><row><entry><para>SUNWadmc</para>
</entry><entry><para>SUNWadmc</para>
</entry><entry><para>SUNWadmlib-sysid</para>
</entry>
</row><row><entry><para>SUNWlibC</para>
</entry><entry><para>SUNWadmfw</para>
</entry><entry><para>SUNWadmr</para>
</entry>
</row><row><entry><para>SUNWbzip</para>
</entry><entry><para>SUNWlibC</para>
</entry><entry><para>SUNWlibC</para>
</entry>
</row><row><entry><para>SUNWgzip</para>
</entry><entry><para>SUNWgzip</para>
</entry><entry><para><emphasis role="strong">For Solaris 10 3/05 only</emphasis>: SUNWgzip</para>
</entry>
</row><row><entry><para>SUNWj2rt</para><note><para>The SUNWj2rt package is needed only under the following conditions:</para><itemizedlist><listitem><para>When you run the Solaris Live Upgrade installer to add Solaris
Live Upgrade packages</para>
</listitem><listitem><para>When you upgrade and use CD media</para>
</listitem>
</itemizedlist>
</note>
</entry><entry><para>SUNWj2rt </para><note><para>The SUNWj2rt package is needed only under the following conditions:</para><itemizedlist><listitem><para>When you run the Solaris Live Upgrade installer to add Solaris
Live Upgrade packages</para>
</listitem><listitem><para>When you upgrade and use CD media</para>
</listitem>
</itemizedlist>
</note>
</entry><entry><para>SUNWj5rt</para><note><para>The SUNWj5rt package is needed only under the following conditions:</para><itemizedlist><listitem><para>When you run the Solaris Live Upgrade installer to add Solaris
Live Upgrade packages</para>
</listitem><listitem><para>When you upgrade and use CD media</para>
</listitem>
</itemizedlist>
</note>
</entry>
</row>
</tbody>
</tgroup>
</table><para>To check for packages on your system, type the following command.</para><screen>% <userinput>pkginfo</userinput> <replaceable>package_name</replaceable></screen>
</sect3>
</sect2><sect2 id="luplanning-8"><title>Solaris Live Upgrade Disk Space Requirements</title><para>Follow general disk space requirements for an upgrade. See <olink targetdoc="solinstallpbiu" targetptr="diskspace-1" remap="external">Chapter 4, <citetitle remap="chapter">System Requirements, Guidelines, and Upgrade (Planning),</citetitle> in <citetitle remap="book">Solaris Express Installation Guide: Planning for Installation and Upgrade</citetitle></olink>.</para><para>To estimate the file system size that is needed
to create a boot environment, start the creation of a new boot environment.
The size is calculated. You can then abort the process.</para><para>The disk on the new boot environment must be able to serve as a boot
device. Some systems restrict which disks can serve as a boot device. Refer
to your system's documentation to determine if any boot restrictions apply.
 </para><para>The disk might need to be prepared before you create the new boot environment.
Check that the disk is formatted properly:</para><itemizedlist><listitem><para>Identify slices large enough to hold the file systems to be
copied.</para>
</listitem><listitem><para>Identify file systems that contain directories that you want
to share between boot environments rather than copy. If you want a directory
to be shared, you need to create a new boot environment with  the directory
put on its own slice. The directory is then a file system and  can be shared
with future boot environments. For more information about creating separate
file systems for sharing, see <olink targetptr="luplanning-16" remap="internal">Guidelines
for Selecting Slices for Shareable File Systems</olink>.</para>
</listitem>
</itemizedlist>
</sect2><sect2 id="luplanning-9"><title>Solaris Live Upgrade Requirements if Creating
RAID-1 Volumes (Mirrors)</title><para>Solaris Live Upgrade uses Solaris Volume Manager technology to create
a boot environment that can contain file systems that are RAID-1 volumes (mirrors).
Solaris Live Upgrade does not implement the full functionality of Solaris
Volume Manager, but does require the following components of Solaris Volume
Manager.</para><table frame="topbot" pgwide="100" id="esqgu"><title>Required Components for
Solaris Live Upgrade and RAID-1 Volumes</title><tgroup cols="3" colsep="0" rowsep="0"><colspec colwidth="32.97*"/><colspec colwidth="67.27*"/><colspec colname="colspec0" colwidth="49.77*"/><thead><row rowsep="1"><entry><para>Requirement </para>
</entry><entry><para>Description</para>
</entry><entry><para>For More Information</para>
</entry>
</row>
</thead><tbody><row><entry><para>You must create at least one state database and at least three state
database replicas. </para>
</entry><entry><para>A state database stores information about disk about the state of your
Solaris Volume Manager configuration. The state database is a collection of
multiple, replicated database copies. Each copy is referred to as a state
database replica. When a state database is copied, the replica protects against
data loss from single points of failure.</para>
</entry><entry><para> For information about creating a state database, see <olink targetdoc="logvolmgradmin" targetptr="about-state-db-replicas-1" remap="external">Chapter 6, <citetitle remap="chapter">State Database (Overview),</citetitle> in <citetitle remap="book">Solaris Volume Manager Administration Guide</citetitle></olink>.</para>
</entry>
</row><row><entry><para>Solaris Live Upgrade supports only a RAID-1 volume (mirror) with single-slice
concatenations on the root (<filename>/</filename>) file system.</para>
</entry><entry><para>A concatenation is a RAID-0 volume. If slices are concatenated, the
data is written to the first available slice until that slice is full. When
that slice is full, the data is written to the next slice, serially. A concatenation
provides no data redundancy unless it is contained in a RAID-1 volume</para><para>A RAID&mdash;1 volume can be comprised of a maximum of three concatenations. </para>
</entry><entry><para>For guidelines about creating mirrored file systems, see <olink targetptr="luplanning-19" remap="internal">Guidelines for Selecting Slices for Mirrored File
Systems</olink>.</para>
</entry>
</row>
</tbody>
</tgroup>
</table>
</sect2>
</sect1><sect1 id="luplanning-12"><title>Upgrading a System With Packages or Patches</title><para>You can use Solaris Live Upgrade to add patches and packages to
a system.  When you use Solaris Live Upgrade, the only downtime the system
incurs is that of a reboot. You can add patches  and packages to a new boot
environment with the <command>luupgrade</command>  command. When you use <command>luupgrade</command> command, you can also use a Solaris Flash archive
to install patches or packages.</para><caution><para>When upgrading and adding and removing packages or patches,
Solaris Live Upgrade requires packages or patches that comply with the SVR4
advanced packaging guidelines. While Sun packages conform to these guidelines,
Sun cannot guarantee the conformance of packages from third-party vendors.
If a package violates these guidelines, the package can cause the package-addition
software during an upgrade to fail or alter the active boot environment. </para><para>For more information about packaging requirements, see <olink targetptr="package-9" remap="internal">Appendix&nbsp;B, Additional SVR4 Packaging Requirements
(Reference)</olink>.</para>
</caution><informaltable frame="topbot" pgwide="100"><tgroup cols="3" colsep="0" rowsep="0"><colspec colwidth="33.58*"/><colspec colname="colspec6" colwidth="58.14*"/><colspec colwidth="58.28*"/><thead><row rowsep="1"><entry><para>Type of Installation</para>
</entry><entry><para>Description</para>
</entry><entry><para>For More Information</para>
</entry>
</row>
</thead><tbody><row><entry><para>Adding patches to a boot environment </para>
</entry><entry><para>Create a new boot environment and use the <command>luupgrade</command> command
with the <option>t</option> option.</para>
</entry><entry><para><olink targetptr="frcbs" remap="internal">To Add Patches to a Network Installation Image
on a Boot Environment</olink></para>
</entry>
</row><row><entry><para>Adding packages to a boot environment</para>
</entry><entry><para>Use the <command>luupgrade</command> command  with the <option>p</option> option.</para>
</entry><entry><para><olink targetptr="frcbp" remap="internal">To Add Packages to a Network Installation Image
on a Boot Environment</olink></para>
</entry>
</row><row><entry><para>Using Solaris Live Upgrade to install a Solaris Flash archive</para>
</entry><entry><para>An archive contains a complete copy of a boot environment with new packages
and patches already included. This copy can be installed on multiple systems.</para>
</entry><entry><itemizedlist><listitem><para>For details about how to create a Solaris Flash archive,
see <olink targetdoc="solinstallflash" targetptr="flashcreate-1" remap="external">Chapter 3, <citetitle remap="chapter">Creating Solaris Flash Archives (Tasks),</citetitle> in <citetitle remap="book">Solaris Express Installation Guide: Solaris Flash Archives (Creation and Installation)</citetitle></olink></para>
</listitem><listitem><para>For information about using Solaris Live Upgrade to install
a Solaris Flash archive, see <olink targetptr="luupgrade-83" remap="internal">Installing
Solaris Flash Archives on a Boot Environment</olink></para>
</listitem>
</itemizedlist>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</sect1><sect1 id="luplanning-11"><title>Guidelines for Creating File Systems With
the <command>lucreate</command> Command</title><para>The <command>lucreate</command> <option>m</option> option
specifies which file systems and the number of file systems to be created
in the new boot environment.  You must specify the exact number of file systems
you want to create by repeating this option. When using the <option>m</option> option
to create file systems, follow these guidelines:</para><itemizedlist><listitem><para>You must specify one <option>m</option> option for the root
(<filename>/</filename>) file system for the new boot environment. If you
run <command>lucreate</command> without the <option>m</option> option, the
Configuration menu is displayed. The Configuration menu enables you to customize
the new boot environment by redirecting files onto new mount points.</para>
</listitem><listitem><para>Any critical file systems that exist in the current boot environment
and that are not specified in a <option>m</option> option are merged into
the next highest-level file system created.</para>
</listitem><listitem><para>Only the file systems that are specified by the <option>m</option> option
are created on the new boot environment. To create the same number of files
systems that is on your current system, you must specify one <option>m</option> option
for each file system to be created.</para><para>For example, a single use
of the <option>m</option> option specifies where to put all the file systems.
You merge all the file systems from the original boot environment into the
one file system that is specified by the <option>m</option> option. If you
specify the <option>m</option> option twice, you create two file systems.
If you have file systems for root (<filename>/</filename>), <filename>/opt</filename>,
and <filename>/var</filename>, you would use one <option>m</option> option
for each file system on the new boot environment.</para>
</listitem><listitem><para>Do not duplicate a mount point. For example, you cannot have
two root (/) file systems.</para>
</listitem>
</itemizedlist>
</sect1><sect1 id="luplanning-50"><title>Guidelines for Selecting Slices for File
Systems</title><para>When you create file systems
for a boot environment, the rules are identical to the rules for creating
file systems for the Solaris OS. Solaris Live Upgrade cannot prevent you from
creating invalid configurations for critical file systems. For example, you
could type a <command>lucreate</command> command that would create separate
file systems for root (<filename>/</filename>) and <filename>/kernel</filename> which
is an invalid division of the root (<filename>/</filename>) file system. </para><para>Do not overlap slices when reslicing disks. If this condition exists,
the new boot environment appears to have been created, but when activated,
the boot environment does not boot. The overlapping file systems might be
corrupted.</para><para>For Solaris Live Upgrade to work properly, the <filename>vfstab</filename> file
on the active boot environment must have valid contents and must have an entry
for the root (<filename>/</filename>) file system at the minimum.</para><sect2 id="luplanning-70"><title>Guidelines for Selecting a Slice for the
root (<filename>/</filename>) File System</title><para>When you create an inactive boot environment, you need to identify
a slice where the root (<filename>/</filename>) file system is to be copied.
Use the following guidelines when you select a slice for the root (<filename>/</filename>)
file system. The slice must comply with the following:</para><itemizedlist><listitem><para>Must be a slice from which the system can boot.</para>
</listitem><listitem><para>Must meet the recommended minimum size.</para>
</listitem><listitem><para>Can be on different physical disks or the same disk as the
active root (<filename>/</filename>) file system.</para>
</listitem><listitem><para>Can be a Veritas Volume Manager volume (VxVM). If VxVM volumes
are configured on your current system, the <command>lucreate</command> command
can create a new boot environment. When the data is copied to the new boot
environment, the Veritas file system configuration is lost and a UFS file
system is created on the new boot environment.</para>
</listitem>
</itemizedlist>
</sect2><sect2 id="luplanning-19"><title>Guidelines for Selecting Slices for Mirrored
File Systems</title><para>You can create a new boot environment that contains
any combination of physical disk slices, Solaris Volume Manager volumes, or
Veritas Volume Manager volumes. Critical file systems that are copied to the
new boot environment can be of the following types: </para><itemizedlist><listitem><para>A physical slice.</para>
</listitem><listitem><para>A single-slice concatenation that is included in a RAID-1
volume (mirror). The slice that contains the root (<filename>/</filename>)
file system can be a RAID-1 volume. </para>
</listitem><listitem><para>A single-slice concatenation that is included in a RAID-0
volume.  The slice that contains the root (<filename>/</filename>) file system
can be a RAID-0 volume.</para>
</listitem>
</itemizedlist><para>When you create a new boot environment, the <command>lucreate</command> <option>m</option> command recognizes the following three types of devices:</para><itemizedlist><listitem><para>A physical slice in the form of /dev/dsk/c<replaceable>w</replaceable>t<replaceable>x</replaceable>d<replaceable>y</replaceable>s<replaceable>z</replaceable></para>
</listitem><listitem><para>A Solaris Volume Manager volume in the form of /dev/md/dsk/d<replaceable>num</replaceable></para>
</listitem><listitem><para>A Veritas Volume Manager volume in the form of /dev/vx/dsk/<replaceable>volume_name</replaceable>.  If VxVM volumes are configured on your current
system, the <command>lucreate</command> command can create a new boot environment.
 When the data is copied to the new boot environment, the Veritas file system
configuration is lost and a UFS file system is created on the new boot environment.</para>
</listitem>
</itemizedlist><note><para>If you have problems upgrading with Veritas VxVM, see <olink targetptr="troubleshooting-48" remap="internal">System Panics When Upgrading With Solaris Live
Upgrade Running Veritas VxVm</olink>.</para>
</note><sect3 id="luplanning-6"><title>General Guidelines When Creating RAID-1 Volumes
(Mirrored) File Systems</title><para>Use the following guidelines to check if a RAID-1 volume is busy, resyncing,
or if volumes contain file systems that are in use by  a Solaris Live Upgrade
boot environment.</para><para>For volume naming guidelines, see <olink targetdoc="solinstallpbiu" targetptr="epudh" remap="external"><citetitle remap="section">RAID Volume Name Requirements and Guidelines for Custom JumpStart and Solaris Live Upgrade</citetitle> in <citetitle remap="book">Solaris Express Installation Guide: Planning for Installation and Upgrade</citetitle></olink>.</para><sect4 id="luplanning-17"><title>Checking Status of Volumes</title><para>If a mirror or submirror needs maintenance or is busy, components cannot
be detached. You should use the <command>metastat</command> command before
creating a new boot environment and using the <literal>detach</literal> keyword.
The <command>metastat</command> command checks if the mirror is in the process
of resynchronization or if the mirror is in use. For information, see the
man page <olink targetdoc="refman1m" targetptr="metastat-1m" remap="external"><citerefentry><refentrytitle>metastat</refentrytitle><manvolnum>1M</manvolnum></citerefentry></olink>.</para>
</sect4><sect4 id="luplanning-18"><title>Detaching Volumes and Resynchronizing Mirrors</title><para>If you use the <literal>detach</literal> keyword to detach a submirror, <command>lucreate</command> checks if a device is currently resyncing. If the device
is resyncing, you cannot detach the submirror and you see an error message.</para><para>Resynchronization is the process of copying data from one submirror
to another submirror after the following problems:</para><itemizedlist><listitem><para>Submirror failures.</para>
</listitem><listitem><para>System crashes.</para>
</listitem><listitem><para>A submirror has been taken offline and brought back online.</para>
</listitem><listitem><para>The addition of a new submirror.</para>
</listitem>
</itemizedlist><para>For more information about resynchronization, see <olink targetdoc="logvolmgradmin" targetptr="about-metadevices-25868" remap="external"><citetitle remap="section">RAID-1 Volume (Mirror) Resynchronization</citetitle> in <citetitle remap="book">Solaris Volume Manager Administration Guide</citetitle></olink>.</para>
</sect4><sect4 id="luplanning-19vol"><title>Using Solaris Volume Manager Commands</title><para>Use the <command>lucreate</command> command rather than Solaris Volume Manager commands to manipulate
volumes on inactive boot environments. The Solaris Volume Manager software
has no knowledge of boot environments, whereas the <command>lucreate</command> command
contains checks that prevent you from inadvertently destroying a boot environment.
For example, <command>lucreate</command> prevents you from overwriting or
deleting a Solaris Volume Manager volume.</para><para>However, if you have already used Solaris Volume Manager software to
create complex Solaris Volume Manager concatenations, stripes, and mirrors,
you must use Solaris Volume Manager software to manipulate them. Solaris Live
Upgrade is aware of these components and supports their use. Before using
Solaris Volume Manager commands that can create, modify, or destroy volume
components, use the <command>lustatus</command> or <command>lufslist</command> commands.
These commands can determine which Solaris Volume Manager volumes contain
file systems that are in use by  a Solaris Live Upgrade boot environment.</para>
</sect4>
</sect3>
</sect2><sect2 id="luplanning-80"><title>Guidelines for Selecting a Slice for a Swap
File System</title><para>These guidelines contain configuration recommendations and examples
for a swap slice.</para><sect3 id="luplanning-14swap"><title>Configuring Swap for the New Boot Environment</title><para>You can configure a swap slice in three ways by using the <command>lucreate</command> command with the <option>m</option> option:</para><itemizedlist><listitem><para>If you do not specify a swap slice, the swap slices belonging
to the current boot environment are configured for the new boot environment. </para>
</listitem><listitem><para>If you specify one or more swap slices, these slices are the
only swap slices that are used by the new boot environment. The two boot environments
do not share any swap slices.</para>
</listitem><listitem><para>You can specify to both share a swap slice and add a new slice
for swap. </para>
</listitem>
</itemizedlist><para>The following examples show the three ways of configuring swap. The
current boot environment is configured with the root (<filename>/</filename>)
file system on <literal>c0t0d0s0</literal>. The swap file system is on <literal>c0t0d0s1</literal>.</para><itemizedlist><listitem><para>In the following example, no swap slice is specified. The
new boot environment contains the root (<filename>/</filename>) file system
on <filename>c0t1d0s0</filename>. Swap is shared between the current and new
boot environment on <literal>c0t0d0s1</literal>.</para><screen># <userinput>lucreate -n be2 -m /:/dev/dsk/c0t1d0s0:ufs</userinput></screen>
</listitem><listitem><para>In the following example, a swap slice is specified. The new
boot environment contains the root (<filename>/</filename>) file system on <filename>c0t1d0s0</filename>. A new swap file system is created on <literal>c0t1d0s1</literal>.
No swap slice is shared between the current and new boot environment.</para><screen># <userinput>lucreate -n be2 -m /:/dev/dsk/c0t1d0s0:ufs -m -:/dev/dsk/c0t1d0s1:swap</userinput></screen>
</listitem><listitem><para>In the following example, a swap slice is added and another
swap slice is shared between the two boot environments. The new boot environment
contains the root (<filename>/</filename>) file system on <filename>c0t1d0s0</filename>.
A new swap slice is created on <literal>c0t1d0s1</literal>. The swap slice
on <literal>c0t0d0s1</literal> is shared between the current and new boot
environment.</para><screen remap="wide"># <userinput>lucreate -n be2 -m /:/dev/dsk/c0t1d0s0:ufs -m -:shared:swap -m -:/dev/dsk/c0t1d0s1:swap</userinput></screen>
</listitem>
</itemizedlist>
</sect3><sect3 id="luplanning-13lu"><title>Failed Boot Environment Creation if Swap
is in Use</title><para>A boot environment creation fails
if the swap slice is being used by any boot environment except for the current
boot environment. If the boot environment was created using the <option>s</option> option,
the alternate-source boot environment can use the swap slice, but not any
other boot environment. </para>
</sect3>
</sect2><sect2 id="luplanning-16"><title>Guidelines for Selecting Slices for Shareable
File Systems</title><para>Solaris Live
Upgrade copies the entire contents of a slice to the designated new boot environment
slice. You might want some large file systems on that slice to be shared between
boot environments rather than copied to conserve space and copying time. File
systems that are critical to the OS such as root (<filename>/</filename>)
and <filename>/var</filename> must be copied. File systems such as <filename>/home</filename> are not critical file systems and could be shared between boot
environments. Shareable file systems must be user-defined file systems and
on separate swap slices on both the active and new boot environments. You
can reconfigure the disk several ways, depending  your needs. </para><informaltable frame="topbot" pgwide="100"><tgroup cols="3" colsep="0" rowsep="0"><colspec colwidth="58.76*"/><colspec colname="colspec0" colwidth="61.28*"/><colspec colwidth="29.97*"/><thead><row><entry rowsep="1"><para>Reconfiguring a disk</para>
</entry><entry rowsep="1"><para>Examples</para>
</entry><entry rowsep="1"><para>For More Information</para>
</entry>
</row>
</thead><tbody><row><entry><para>You can reslice the disk before creating the new boot environment and
put the shareable file system on its own slice. </para>
</entry><entry><para>For example, if the root (<filename>/</filename>) file system, <filename>/var</filename>, and <filename>/home</filename> are on the same slice, reconfigure
the disk and put <filename>/home</filename> on its own slice. When you create
any new boot environments, <filename>/home</filename> is shared with the new
boot environment by default.</para>
</entry><entry><para><olink targetdoc="refman1m" targetptr="format-1m" remap="external"><citerefentry><refentrytitle>format</refentrytitle><manvolnum>1M</manvolnum></citerefentry></olink></para>
</entry>
</row><row><entry><para>If you want to share a directory, the directory must be split off to
its own slice. The directory is then a file system that can be shared with
another boot environment. You can use the <command>lucreate</command> command
with the <option>m</option> option to create a new boot environment and split
a directory off to its own slice. But, the new file system cannot yet be shared
with the original boot environment. You need to run the <command>lucreate</command> command
with the <option>m</option> option again to create another boot environment.
The two new boot environments can then share the directory. </para>
</entry><entry><para>For example, if you wanted to upgrade from the  Solaris 9 release to
the Solaris Express 5/07 release and share <filename>/home</filename>,
you could run the <command>lucreate</command> command with the <option>m</option> option.
You could  create a Solaris 9 release with <filename>/home</filename> as a
separate file system on its own slice. Then run the <command>lucreate</command> command
with the <option>m</option> option again to duplicate that boot environment.
This third boot environment can then be upgraded to the Solaris Express 5/07 release. <filename>/home</filename> is shared between the Solaris 9 and Solaris Express 5/07 releases. </para>
</entry><entry><para>For a description of shareable and critical file systems, see <olink targetptr="luoverview-13" remap="internal">File System Types</olink>.</para>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</sect2>
</sect1><sect1 id="luplanning-4"><title>Customizing a New Boot Environment's Content</title><para>When you
create a new boot environment, some directories and  files can be excluded
from a copy to the new boot environment. If you have excluded a directory,
you can also reinstate specified subdirectories or files under the excluded
directory. These subdirectories or files that have been restored are then
copied to the new boot environment. For example, you could exclude from the
copy all files and directories in <filename>/etc/mail</filename>, but include
all files and directories in <filename>/etc/mail/staff</filename>. The following
command copies the <filename>staff</filename> subdirectory to the new boot
environment.</para><screen># <userinput>lucreate -n second_disk -x /etc/mail -y /etc/mail/staff</userinput></screen><caution><para>Use the file-exclusion options with caution. Do not remove
files or directories that are required by the system.</para>
</caution><para>The following table lists the <command>lucreate</command> command options
for removing and restoring directories and files.</para><informaltable frame="topbot"><tgroup cols="3" colsep="0" rowsep="0"><colspec colwidth="50*"/><colspec colname="colspec0" colwidth="50.00*"/><colspec colwidth="50*"/><thead><row rowsep="1"><entry><para>How Specified?</para>
</entry><entry><para>Exclude Options </para>
</entry><entry><para>Include Options</para>
</entry>
</row>
</thead><tbody><row><entry><para>Specify the name of the directory or file</para>
</entry><entry><para><option>x</option> <replaceable>exclude_dir</replaceable></para>
</entry><entry><para><option>y</option> <replaceable>include_dir</replaceable></para>
</entry>
</row><row><entry><para>Use a file that contains a list</para>
</entry><entry><para><option>f</option>  <replaceable>list_filename</replaceable></para><para><option>z</option> <replaceable>list_filename</replaceable></para>
</entry><entry><para><option>Y</option>  <replaceable>list_filename</replaceable></para><para><option>z</option>  <replaceable>list_filename</replaceable></para>
</entry>
</row>
</tbody>
</tgroup>
</informaltable><para>For examples of customizing the directories and files when creating
a boot environment, see <olink targetptr="lucreate-1601" remap="internal">To Create a Boot
Environment and Customize the Content</olink>.</para>
</sect1><sect1 id="luplanning-10"><title>Synchronizing Files Between Boot Environments</title><para>When you are ready to switch and
make the new boot environment active, you quickly activate the new boot environment
and reboot. Files are synchronized between boot environments the first time
that you boot a newly created boot environment. &ldquo;Synchronize&rdquo;
means that certain critical system files and directories might be copied from
the last-active boot environment to the boot environment being booted. Those
files and directories that have changed are copied.</para><sect2 id="luplanning-1210"><title>Adding Files to the <filename>/etc/lu/synclist</filename></title><para>Solaris Live Upgrade checks for critical files that have changed. If
these files' content is not the same in both boot environments, they are copied
from the active boot environment to the new boot environment. Synchronizing
is meant for critical files such as <filename>/etc/passwd</filename> or <filename>/etc/group</filename> files that might have changed since the new boot environment
was created.</para><para>The <filename>/etc/lu/synclist</filename> file contains a list of directories
and files that are synchronized. In some instances, you might want to copy
other files from the active boot environment to the new boot environment.
You can add directories and files to <filename>/etc/lu/synclist</filename> if
necessary.</para><para>Adding files not listed in the <filename>/etc/lu/synclist</filename> could
cause a system to become unbootable. The synchronization process only copies
files and creates directories. The process does not remove files and directories.</para><para>The following example of the <filename>/etc/lu/synclist</filename> file
shows the standard directories and files that are synchronized for this system.</para><screen>/var/mail                    OVERWRITE
/var/spool/mqueue            OVERWRITE
/var/spool/cron/crontabs     OVERWRITE
/var/dhcp                    OVERWRITE
/etc/passwd                  OVERWRITE
/etc/shadow                  OVERWRITE
/etc/opasswd                 OVERWRITE
/etc/oshadow                 OVERWRITE
/etc/group                   OVERWRITE
/etc/pwhist                  OVERWRITE
/etc/default/passwd          OVERWRITE
/etc/dfs                     OVERWRITE
/var/log/syslog              APPEND
/var/adm/messages            APPEND</screen><para>Examples of directories and files that might be appropriate to add to
the <filename>synclist</filename> file are the following:</para><screen>/var/yp                    OVERWRITE
/etc/mail                  OVERWRITE
/etc/resolv.conf           OVERWRITE
/etc/domainname            OVERWRITE</screen><para>The <filename>synclist</filename> file entries can be files or directories.
The second field is the method of updating that occurs on the activation of
the boot environment. You can choose from three methods to update files: </para><itemizedlist><listitem><para>OVERWRITE &ndash; The contents of the active boot environment's
file overwrites the contents of the new boot environment file. OVERWRITE is
the default action if no action is specified in the second field. If the entry
is a directory, all subdirectories are copied. All files are overwritten.
The new boot environment file has the same date, mode, and ownership as the
same file on the previous boot environment. </para>
</listitem><listitem><para>APPEND &ndash; The contents of the active boot environment's
file are added to the end of the new boot environment's file. This addition
might lead to duplicate entries in the file. Directories cannot be listed
as APPEND. The new boot environment file has the same date, mode, and ownership
as the same file on the previous boot environment. </para>
</listitem><listitem><para>PREPEND &ndash; The contents of the active boot environment's
file are added to the beginning of the new boot environment's file. This addition
might lead to duplicate entries in the file. Directories can not be listed
as PREPEND. The new boot environment file has the same date, mode, and ownership
as the same file on the previous boot environment. </para>
</listitem>
</itemizedlist>
</sect2><sect2 id="luplanning-1110"><title>Forcing a Synchronization Between Boot
Environments</title><para>The first time you boot from a newly created boot environment, Solaris
Live Upgrade synchronizes the new boot environment with the boot environment
that was last active.  After this initial boot and synchronization, Solaris
Live Upgrade does not perform a synchronization unless requested. To force
a synchronization, you use the <command>luactivate</command> command with
the <option>s</option> option.</para><para>You might want to force a synchronization if you are maintaining multiple
versions of the Solaris OS. You might want changes in files such as <filename>email</filename> or <filename>passwd/group</filename> to be in the boot environment
you are activating to. If you force a synchronization, Solaris Live Upgrade
checks for conflicts between files that are subject to synchronization. When
the new boot environment is booted and a conflict is detected, a warning is
issued and the files are not synchronized.  Activation can be completed successfully,
despite such a conflict. A conflict can occur if you make changes to the same
file on both the new boot environment and the active boot environment. For
example, you make changes to the <filename>/etc/passwd</filename> file on
the original boot environment. Then you make other changes to <filename>/etc/passwd</filename> file on the new boot environment. The synchronization process
cannot choose which file to copy for the synchronization.</para><caution><para>Use this option with great care, because you  might not  be
aware of or in control of changes that might have occurred in the last-active
 boot environment. For example, if you were running Solaris Express 5/07 software
on your current boot environment and booted back to a Solaris 9 release with
a forced synchronization, files could be changed on the Solaris 9 release.
Because files are dependent on the release of the OS, the boot to the Solaris
9 release could fail because the Solaris Express 5/07 files might not
be compatible with the Solaris 9 files.</para>
</caution>
</sect2>
</sect1><sect1 id="gacex" arch="x86"><title>Activating a Boot Environment With the
GRUB Menu</title><para><emphasis role="strong">Starting with the Solaris 10 1/06 release</emphasis>,
a GRUB boot menu provides an optional method of switching between boot environments.
The GRUB menu is an alternative to activating with the <command>luactivate</command> command.</para><informaltable frame="topbot"><tgroup cols="2" colsep="0" rowsep="0"><colspec colwidth="50*"/><colspec colwidth="50*"/><thead><row rowsep="1"><entry><para>Task</para>
</entry><entry><para>Information</para>
</entry>
</row>
</thead><tbody><row><entry><para>To activate a boot environment with the GRUB menu</para>
</entry><entry><para><olink targetptr="gacps" remap="internal">To Activate a Boot Environment With the GRUB
Menu</olink></para>
</entry>
</row><row><entry><para>To fall back to the original boot environment with a GRUB menu</para>
</entry><entry><para><olink targetptr="gaciv" remap="internal">To Fall Back Despite Successful New Boot Environment
Activation With the GRUB Menu</olink></para>
</entry>
</row><row><entry><para>For overview and planning information for GRUB</para>
</entry><entry><para><olink targetdoc="solinstallpbiu" targetptr="grub-1" remap="external">Chapter 6, <citetitle remap="chapter">GRUB Based Booting for Solaris Installation,</citetitle> in <citetitle remap="book">Solaris Express Installation Guide: Planning for Installation and Upgrade</citetitle></olink></para>
</entry>
</row><row><entry><para>For a complete GRUB overview and system administration tasks</para>
</entry><entry><para><olink targetdoc="sysadv1" remap="external"><citetitle remap="book">System Administration Guide: Basic Administration</citetitle></olink></para>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</sect1><sect1 id="gepqv"><title>Solaris Live Upgrade Character User Interface</title><para>Sun no longer recommends use of the <command>lu</command> command. The <command>lu</command> command displays a character user interface (CUI). The underlying
command sequence for the CUI, typically the <command>lucreate</command>, <command>luupgrade</command>, and <command>luactivate</command> commands, is straightforward
to use. Procedures for these commands are provided in the following chapters.</para>
</sect1>
</chapter>